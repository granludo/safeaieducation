
DRAFT not for publication yet

# AI in Education Integration Checklist

This checklist is designed to guide the evaluation and integration of AI tools in educational settings, ensuring they align with the principles of the Safe AI in Education Manifesto.

This checklist is designed to be used by educators, technologists, and educational institutions to evaluate and integrate AI tools in education. 

[
Transparency requirements

Generative AI, like ChatGPT, will not be classified as high-risk, but will have to comply with transparency requirements and EU copyright law:
Disclosing that the content was generated by AI
Designing the model to prevent it from generating illegal content
Publishing summaries of copyrighted data used for training
 
High-impact general-purpose AI models that might pose systemic risk, such as the more advanced AI model GPT-4, would have to undergo thorough evaluations and any serious incidents would have to be reported to the European Commission.

Content that is either generated or modified with the help of AI - images, audio or video files (for example deepfakes) - need to be clearly labelled as AI generated so that users are aware when they come across such content.
]

## Principle 1: Guaranteeing Confidentiality

- [ ] **Ownership and Control of Technology Stack of the AI Educational Tool**  
  - Does the institution own and control the entire technology stack of the AI Educational Tool?
    - [ ] If the tool runs **on-premises** infrastructure, confirm the institution fully owns and manages all infrastructure and is responsible for maintaining compliance with privacy regulations (GDPR (Europe) and FERPA (USA)).
    - [ ] If the tool runs fully or partialy on **cloud-based** infrastructure, ensure the cloud provider and the service agreement is:
      - **Certified** for privacy and security compliance.
      - Has clear **terms of service** that outline data protection responsibilities.
    - [ ] If provided **as a service** (SaaS), verify the service vendor’s:
      - **Certifications** for GDPR and FERPA compliance.
      - Clearly defined **terms of service** that outline data usage, security measures, and shared responsibilities.
    - [ ] If the tool makes use of Generative AI models via API to AI vendors:
      - All communication between the tool and the AI vendor is encrypted.  
      - Its is assured that no personal information is sent to AI Models. 
      - External vendors supplying AI engines or models are **compliant with privacy regulations**, and it is ensured that data shared with vendors will not be used for other purposes than the provision of the AI Educational Tool.
      - There are clear **service-level agreements (SLAs)** or **terms of service** in place for vendor APIs, including compliance and QoS guarantees.
      - Is there full transparency from the vendor on how data is used, stored, and shared?
      - Are there clear policies for data retention, and can data be securely deleted upon request?

- [ ] **Data Ownership and Control**  
    - [ ] The interactions of students with the AI Educational Tool are protected by the AI vendor's terms of service and service-level agreements (SLAs).
       - The educational institution retains full ownership and control of all personal student data?
       - If a third party AI vendor is used, are the student interactions with the AI Educational Tool protected by the AI vendor's terms of service and service-level agreements (SLAs)?
       - Are strict access controls in place to ensure only authorized personnel can access student data?
    - [ ] The educational institution is responsible and retains full ownership and control of student and teacher authentication and access to the tool.
       - The tool does not require students to register with external services.
    - [ ] Are student personal information and interactions with the tool encrypted both at rest and during transmission?
- [ ] **User Awareness of Data Processing**  
  - Does the interface clearly inform users about how their data is being processed and used?
  - If the tool gathers data from students, does it provide clear information about the types of data collected and how it will be used?
- [ ] **Research Use of Log Data**  
  - If the tool logs are to be used for research purposes, does it provide clear information about the types of data that will be logged and how it will be used?
  - Permission to use the log data for research purposes is obtained from the institution and the students.
- [ ] **Compliance with Privacy Laws**  
  - Does the tool comply with relevant data protection regulations (e.g., GDPR, FERPA)?
- [ ] **Data Minimization**  
  - Does the tool collect only the necessary data required for educational purposes?  

## 2. Alignment with Educational Goals and Practices

- [ ] **Support for Learning Objectives**  
  - Does the AI tool directly support the institution’s specific learning objectives and educational outcomes?
- [ ] **Design for Educational Contexts**  
  - Is the tool specifically designed for educational use, aligning with established teaching methodologies and didactic models?
- [ ] **Adaptability to Teaching Styles**  
  - Can the tool adapt to various teaching methods and instructional designs?
- [ ] **Enhancement of Teaching Practices**  
  - Does the tool enhance teaching without introducing unnecessary complexity or increasing cognitive load?
- [ ] **Assessment Alignment**  
  - Does the tool align with the institution’s assessment strategies and practices?
- [ ] **Prevention of Unethical Practices**  
  - Does the tool have mechanisms to prevent unethical practices such as cheating and plagiarism?

## 3. Usability and Accessibility

- [ ] **User-Friendly Interface**  
  - Is the tool intuitive and easy to use for both educators and students, without requiring extensive technical expertise?
- [ ] **Accessibility for All Users**  
  - Is the tool accessible to users with different abilities and needs, complying with accessibility standards?
- [ ] **Customization Options**  
  - Can the tool be customized to meet the specific needs of different users or contexts?
- [ ] **Minimal Disruption**  
  - Does the tool integrate smoothly into existing workflows and teaching practices?
- [ ] **Student-Centered Learning Support**  
  - Does the tool encourage active engagement and support student-centered learning?

## 4. Accuracy, Explainability, and Reliability

- [ ] **Accuracy of Outputs**  
  - Does the AI tool consistently provide accurate and reliable information relevant to education?
- [ ] **Explainability**  
  - Does the tool provide clear explanations for its outputs and how it arrives at conclusions?
- [ ] **Source Transparency**  
  - Does the tool reference its sources or explain where information comes from?
- [ ] **Error Minimization and Handling**  
  - Are there mechanisms to minimize errors and hallucinations, and does the tool handle errors gracefully?
- [ ] **User Control Over Outputs**  
  - Can users verify, correct, or reject AI-generated outputs when necessary?
- [ ] **Appropriate Confidence Levels**  
  - Does the tool provide information with appropriate confidence levels, avoiding overstatements?
- [ ] **Continuous Monitoring and Feedback**  
  - Is there a system for continuous monitoring and feedback to maintain accuracy over time?

## 5. Ethical Considerations and Transparency

- [ ] **Ethical Training of AI**  
  - Was the AI model trained ethically, with transparency about the sources of training data and methodologies used?
- [ ] **Bias Minimization**  
  - Has the tool taken steps to identify and minimize biases in its training and outputs?
- [ ] **Vendor's Ethical Commitment**  
  - Does the vendor demonstrate a commitment to ethical AI development in education?
- [ ] **Transparency of Limitations**  
  - Are users informed about the limitations of the AI tool based on its training data and design?
- [ ] **Disclosure of Potential Biases**  
  - Does the tool clearly indicate when outputs might be limited or biased due to gaps in training data?

## 6. Integration and Compatibility

- [ ] **Compatibility with Existing Systems**  
  - Is the AI tool compatible with the institution’s existing technology infrastructure (e.g., LMS, educational software)?
- [ ] **Technology Stack Integration**  
  - Can the tool be fully integrated into the institution's technology stack without reliance on external infrastructure?
- [ ] **Scalability**  
  - Can the tool scale to accommodate different class sizes, courses, and institutional needs?

## 7. Support and Training

- [ ] **Vendor Support**  
  - Does the vendor provide sufficient training and support for educators and IT staff?
- [ ] **Feedback Mechanisms**  
  - Does the tool provide ways for users to give feedback or report issues?
- [ ] **Ongoing Updates and Ethical Compliance**  
  - Is there ongoing monitoring and updating to ensure continued ethical compliance and performance?
